nohup: 忽略输入
ckpt/source/pda/office-home/A
Namespace(batch_size=64, bottleneck=256, class_num=50, classifier='bn', cls_par=0.6, da='pda', distance='cosine', dset='office-home', ent=True, ent_par=1.0, epsilon=1e-05, extra_class=1, gent=True, gpu_id='1', interval=10, issave=False, layer='wn', lr=0.01, lr_decay1=0.1, lr_decay2=1.0, max_epoch=10, name='office-home', name1='AC', name2='AR', name3='AP', net='resnet50', out_file=<_io.TextIOWrapper name='ckpt/target/pda/office-home-addfc+gent/log_par_0.6_thr0.txt' mode='w' encoding='UTF-8'>, output='ckpt/target', output_dir='ckpt/target/pda/office-home-addfc+gent', output_dir_src='ckpt/source/pda/office-home/A', output_src='ckpt/source', s=0, s_dset_path='./data/office-home/Art.txt', savename='par_0.6_thr0', seed=2020, src_classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], t=1, t_dset_path='./data/office-home/Clipart.txt', t_dset_path1='./data/office-home/Real_World.txt', t_dset_path2='./data/office-home/Product.txt', tar_classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], tar_classes1=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], tar_classes2=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64], test_dset_path='./data/office-home/Clipart.txt', test_dset_path1='./data/office-home/Real_World.txt', test_dset_path2='./data/office-home/Product.txt', threshold=0, worker=4)
/homes/jh015/.conda/envs/hj_trans/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/homes/jh015/.conda/envs/hj_trans/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
ent tensor(0.3171) tensor(0.4742) tensor(17.6251, dtype=torch.float64) tensor(9.1083, dtype=torch.float64)
all_output1 tensor([0.0056, 0.0235, 0.0069, 0.0125, 0.0122, 0.0118, 0.0037, 0.0027, 0.0037,
        0.0290, 0.0100, 0.0155, 0.0122, 0.0039, 0.0093, 0.0039, 0.0171, 0.0161,
        0.0108, 0.0192, 0.0043, 0.0144, 0.0038, 0.0094, 0.0059, 0.0044, 0.0099,
        0.0065, 0.0096, 0.0048, 0.0047, 0.0078, 0.0023, 0.0114, 0.0050, 0.0110,
        0.0060, 0.0047, 0.0076, 0.0092, 0.0156, 0.0106, 0.0159, 0.0114, 0.0161,
        0.0060, 0.0069, 0.0111, 0.0123, 0.0197, 0.5020])
cls_count [7.000e+00 6.000e+01 1.700e+01 3.200e+01 2.900e+01 3.300e+01 5.000e+00
 2.000e+00 1.000e+00 9.300e+01 2.800e+01 1.600e+01 3.200e+01 2.000e+00
 1.300e+01 1.000e+00 3.800e+01 3.100e+01 2.200e+01 6.800e+01 1.000e+00
 4.800e+01 5.000e+00 1.200e+01 1.200e+01 6.000e+00 2.000e+01 1.000e+01
 1.900e+01 5.000e+00 7.000e+00 5.000e+00 2.000e+00 3.600e+01 9.000e+00
 2.500e+01 1.000e+01 4.000e+00 1.500e+01 2.800e+01 3.400e+01 2.800e+01
 3.500e+01 2.300e+01 5.000e+01 3.000e+00 1.700e+01 2.800e+01 3.800e+01
 5.800e+01 2.258e+03] 0.0004428697962798937 3381.0 0.009946855624446414 0.6678497485950903
Accuracy = 50.37% -> 55.16%

50
ent tensor(0.2563) tensor(0.3048) tensor(16.1697, dtype=torch.float64) tensor(13.4867, dtype=torch.float64)
all_output1 tensor([0.0182, 0.0365, 0.0346, 0.0260, 0.0167, 0.0216, 0.0140, 0.0058, 0.0204,
        0.0399, 0.0221, 0.0092, 0.0250, 0.0247, 0.0140, 0.0282, 0.0181, 0.0236,
        0.0232, 0.0532, 0.0135, 0.0244, 0.0089, 0.0142, 0.0280, 0.0017, 0.0020,
        0.0030, 0.0041, 0.0019, 0.0031, 0.0031, 0.0028, 0.0015, 0.0025, 0.0017,
        0.0038, 0.0025, 0.0026, 0.0019, 0.0021, 0.0030, 0.0039, 0.0041, 0.0028,
        0.0029, 0.0028, 0.0044, 0.0022, 0.0130, 0.3563])
cls_count [ 31.  67.  70.  49.  25.  36.  18.   7.  33.  71.  39.  10.  45.  46.
  20.  48.  28.  35.  40.  97.  19.  46.  13.  21.  46.   0.   0.   0.
   2.   0.   1.   1.   2.   0.   1.   0.   0.   0.   1.   0.   1.   2.
   1.   2.   0.   0.   1.   2.   1.  22. 730.] 0.0 1730.0 0.0273972602739726 0.4219653179190751
Accuracy = 76.01% -> 80.75%

23
ent tensor(0.2983) tensor(0.4244) tensor(17.8864, dtype=torch.float64) tensor(17.8864, dtype=torch.float64)
cls_count [  57.   52.   28.   56.    8.   57.   19.    0.   24.   76.   32.    8.
   43.   12.   13.   18.   34.   19.   64.   39.    0.   30.   27.   17.
    6.   13.   53.   16.   57.   24.   59.   25.   69.   43.    5.   28.
   44.   26.   17.   39.   41.   15.   72.   68.   14.    4.   33.   44.
   53.  133. 2705.] 0.0 4439.0 0.012820702402957487 0.6093714800630773
cls_count [ 57.  52.  28.  56.   8.  57.  19.   0.  24.  76.  32.   8.  43.  12.
  13.  18.  34.  19.  64.  39.   0.  30.  27.  17.   6.  13.  53.  16.
  57.  24.  59.  25.  69.  43.   5.  28.  44.  26.  17.  39.  41.  15.
  72.  68.  14.   4.  33.  44.  53. 133.] 0.0 0.0 133.0 0.0
51
acc [83.58208955 76.11940299 25.80645161 80.59701493  4.16666667 70.42253521
 24.48979592  0.         52.17391304 60.60606061 38.88888889  5.55555556
 42.42424242 11.11111111 17.5        37.20930233 52.63157895 16.66666667
 64.77272727 88.63636364  0.         68.29268293 27.55102041  9.63855422
 10.34482759 14.44444444 55.20833333 23.33333333 45.91836735 33.33333333
 59.5959596  16.12903226 69.6969697  54.43037975 11.62790698 55.31914894
 41.93548387 20.93023256 27.5862069  67.24137931 54.28571429 35.
 58.06451613 67.67676768 13.13131313  9.75609756 61.70212766 35.35353535
 62.96296296 98.7654321  89.36627282] 51 H_score 56.44780779028817
Task: office-home, Iter:0/700; Accuracy = 42.20% / 41.25% / 89.37%
ent tensor(0.1313) tensor(0.1198) tensor(5.4088, dtype=torch.float64) tensor(5.5309, dtype=torch.float64)
all_output1 tensor([0.0103, 0.0502, 0.0167, 0.0213, 0.0222, 0.0254, 0.0096, 0.0099, 0.0042,
        0.0352, 0.0127, 0.0299, 0.0199, 0.0155, 0.0224, 0.0199, 0.0209, 0.0175,
        0.0233, 0.0250, 0.0223, 0.0213, 0.0059, 0.0190, 0.0090, 0.0139, 0.0253,
        0.0100, 0.0194, 0.0133, 0.0114, 0.0251, 0.0096, 0.0159, 0.0152, 0.0189,
        0.0133, 0.0121, 0.0143, 0.0133, 0.0216, 0.0153, 0.0236, 0.0191, 0.0287,
        0.0093, 0.0125, 0.0283, 0.0203, 0.0223, 0.0789])
cls_count [ 33. 175.  56.  69.  78.  88.  29.  35.  14. 121.  43. 100.  68.  53.
  80.  73.  69.  65.  76.  86.  73.  74.  23.  61.  27.  46.  88.  35.
  66.  44.  36.  81.  30.  52.  55.  64.  41.  43.  46.  45.  81.  51.
  85.  67.  98.  31.  42.  99.  72.  78. 236.] 0.059322033898305086 3381.0 0.26652542372881355 0.06980183377698901
Accuracy = 56.64% -> 56.40%

50
ent tensor(0.1124) tensor(0.0963) tensor(6.8420, dtype=torch.float64) tensor(7.0843, dtype=torch.float64)
all_output1 tensor([0.0302, 0.0491, 0.0456, 0.0348, 0.0277, 0.0346, 0.0366, 0.0046, 0.0353,
        0.0426, 0.0309, 0.0262, 0.0429, 0.0369, 0.0263, 0.0446, 0.0335, 0.0350,
        0.0380, 0.0568, 0.0251, 0.0362, 0.0097, 0.0294, 0.0340, 0.0016, 0.0008,
        0.0010, 0.0027, 0.0007, 0.0014, 0.0017, 0.0017, 0.0012, 0.0014, 0.0007,
        0.0027, 0.0008, 0.0025, 0.0007, 0.0014, 0.0017, 0.0026, 0.0011, 0.0031,
        0.0006, 0.0019, 0.0030, 0.0015, 0.0105, 0.1045])
cls_count [ 56.  86.  80.  63.  50.  62.  66.   7.  68.  73.  55.  47.  78.  72.
  48.  81.  63.  64.  69. 100.  42.  67.  18.  55.  57.   1.   0.   0.
   3.   0.   1.   1.   1.   2.   1.   0.   1.   0.   3.   0.   2.   1.
   3.   1.   3.   0.   3.   3.   2.  20. 151.] 0.0 1730.0 0.2091390728476821 0.08728323699421969
Accuracy = 80.87% -> 80.00%

24
ent tensor(0.2018) tensor(0.3895) tensor(21.6026, dtype=torch.float64) tensor(21.6026, dtype=torch.float64)
cls_count [  68.   70.   40.   62.   15.   62.   33.    4.   33.   89.   50.   20.
   78.   31.   15.   33.   34.   18.   87.   41.    8.   51.   60.   35.
    8.   51.   73.    6.   69.   39.   67.   34.   88.   58.    7.   39.
   55.   41.   35.   45.   55.   23.   93.   88.   20.    7.   44.   69.
   71.  132. 2085.] 0.0019184652278177458 4439.0 0.022580335731414866 0.4697003829691372
cls_count [ 68.  70.  40.  62.  15.  62.  33.   4.  33.  89.  50.  20.  78.  31.
  15.  33.  34.  18.  87.  41.   8.  51.  60.  35.   8.  51.  73.   6.
  69.  39.  67.  34.  88.  58.   7.  39.  55.  41.  35.  45.  55.  23.
  93.  88.  20.   7.  44.  69.  71. 132.] 0.0 4.0 132.0 0.030303030303030304
51
acc [92.53731343 98.50746269 40.32258065 88.05970149  9.375      80.28169014
 30.6122449   4.44444444 71.73913043 67.67676768 54.16666667 16.66666667
 72.72727273 31.31313131 25.         62.79069767 57.89473684 19.04761905
 82.95454545 90.90909091 10.52631579 85.36585366 61.2244898  25.30120482
  8.62068966 47.77777778 69.79166667 10.         56.12244898 52.77777778
 67.67676768 21.50537634 83.83838384 68.35443038 13.95348837 80.85106383
 48.38709677 27.90697674 58.62068966 77.5862069  67.14285714 52.5
 74.19354839 85.85858586 14.14141414 12.19512195 76.59574468 51.51515152
 85.18518519 97.5308642  86.89581096] 51 H_score 66.45647746065372
Task: office-home, Iter:70/700; Accuracy = 54.45% / 53.80% / 86.90%
ent tensor(0.0954) tensor(0.0769) tensor(4.4250, dtype=torch.float64) tensor(4.5613, dtype=torch.float64)
all_output1 tensor([0.0106, 0.0494, 0.0189, 0.0227, 0.0225, 0.0258, 0.0095, 0.0106, 0.0047,
        0.0337, 0.0120, 0.0280, 0.0190, 0.0127, 0.0246, 0.0200, 0.0223, 0.0185,
        0.0214, 0.0240, 0.0237, 0.0208, 0.0078, 0.0169, 0.0078, 0.0153, 0.0271,
        0.0124, 0.0182, 0.0150, 0.0119, 0.0226, 0.0102, 0.0151, 0.0162, 0.0196,
        0.0132, 0.0136, 0.0131, 0.0143, 0.0226, 0.0152, 0.0246, 0.0194, 0.0257,
        0.0115, 0.0137, 0.0268, 0.0198, 0.0221, 0.0728])
cls_count [ 36. 182.  67.  80.  77.  89.  31.  37.  15. 118.  39.  94.  64.  45.
  85.  68.  74.  64.  74.  82.  85.  71.  26.  58.  26.  49.  95.  44.
  66.  56.  40.  82.  33.  51.  57.  67.  43.  44.  45.  48.  77.  52.
  84.  68.  92.  40.  50.  91.  70.  75. 175.] 0.08571428571428572 3381.0 0.3664 0.051759834368530044
Accuracy = 57.23% -> 56.73%

50
ent tensor(0.0858) tensor(0.0585) tensor(7.1606, dtype=torch.float64) tensor(7.5930, dtype=torch.float64)
all_output1 tensor([0.0315, 0.0472, 0.0458, 0.0360, 0.0278, 0.0332, 0.0359, 0.0028, 0.0385,
        0.0409, 0.0327, 0.0287, 0.0437, 0.0385, 0.0301, 0.0460, 0.0369, 0.0380,
        0.0368, 0.0552, 0.0231, 0.0374, 0.0127, 0.0287, 0.0268, 0.0008, 0.0004,
        0.0006, 0.0018, 0.0006, 0.0008, 0.0008, 0.0004, 0.0007, 0.0009, 0.0003,
        0.0008, 0.0007, 0.0012, 0.0004, 0.0013, 0.0010, 0.0014, 0.0005, 0.0005,
        0.0003, 0.0014, 0.0020, 0.0011, 0.0143, 0.1101])
cls_count [ 56.  83.  81.  63.  48.  61.  64.   5.  68.  72.  61.  52.  79.  72.
  56.  83.  67.  68.  66.  99.  43.  67.  24.  52.  47.   0.   0.   0.
   3.   0.   1.   0.   0.   1.   1.   0.   0.   1.   1.   0.   2.   1.
   0.   0.   0.   0.   3.   3.   1.  26. 149.] 0.0 1730.0 0.21221476510067114 0.08612716763005779
Accuracy = 81.50% -> 79.94%

24
ent tensor(0.1205) tensor(0.3570) tensor(28.8769, dtype=torch.float64) tensor(28.8769, dtype=torch.float64)
cls_count [  64.   68.   48.   63.   12.   60.   36.    3.   36.   92.   50.   26.
   88.   43.   13.   34.   41.   20.   87.   39.    4.   49.   68.   32.
    4.   58.   74.   10.   67.   44.   64.   36.   87.   60.    6.   40.
   50.   48.   40.   46.   54.   25.   88.   89.   17.    6.   39.   72.
   73.  134. 2032.] 0.0014763779527559055 4439.0 0.023690944881889765 0.45776075692723583
cls_count [ 64.  68.  48.  63.  12.  60.  36.   3.  36.  92.  50.  26.  88.  43.
  13.  34.  41.  20.  87.  39.   4.  49.  68.  32.   4.  58.  74.  10.
  67.  44.  64.  36.  87.  60.   6.  40.  50.  48.  40.  46.  54.  25.
  88.  89.  17.   6.  39.  72.  73. 134.] 0.0 3.0 134.0 0.022388059701492536
51
acc [91.04477612 98.50746269 45.16129032 89.55223881  8.33333333 78.87323944
 36.73469388  4.44444444 78.26086957 71.71717172 55.55555556 21.11111111
 84.84848485 43.43434343 22.5        65.11627907 70.1754386  26.19047619
 82.95454545 88.63636364  7.89473684 85.36585366 69.3877551  21.68674699
  6.89655172 58.88888889 71.875      16.66666667 53.06122449 59.72222222
 64.64646465 20.43010753 85.85858586 72.15189873 13.95348837 82.9787234
 48.38709677 25.58139535 67.24137931 79.31034483 70.         52.5
 74.19354839 86.86868687 14.14141414 14.63414634 74.46808511 55.55555556
 87.65432099 97.5308642  86.89581096] 51 H_score 68.14756473771914
Task: office-home, Iter:140/700; Accuracy = 56.66% / 56.05% / 86.90%
