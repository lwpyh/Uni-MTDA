nohup: 忽略输入
ckpt/source/oda/office-home/P
Namespace(batch_size=64, bottleneck=256, class_num=25, classifier='bn', cls_par=0.6, da='oda', distance='cosine', dset='office-home', ent=True, ent_par=1.0, epsilon=1e-05, extra_class=1, gent=True, gpu_id='1', interval=20, issave=False, layer='wn', lr=0.01, lr_decay1=0.1, lr_decay2=1.0, max_epoch=20, name='office-home', name1='PR', net='resnet50', out_file=<_io.TextIOWrapper name='ckpt/target/oda/office-home-addfc+gent/log_par_0.6.txt' mode='w' encoding='UTF-8'>, output='ckpt/target', output_dir='ckpt/target/oda/office-home-addfc+gent', output_dir_src='ckpt/source/oda/office-home/P', output_src='ckpt/source', s=0, s_dset_path='./data/office-home/Product.txt', savename='par_0.6', seed=2020, src_classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], t=1, t_dset_path='./data/office-home/Real_World.txt', tar_classes=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64], test_dset_path='./data/office-home/Real_World.txt', threshold=0, worker=4)
/homes/jh015/.conda/envs/hj_trans/lib/python3.7/site-packages/torchvision/models/_utils.py:209: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  f"The parameter '{pretrained_param}' is deprecated since 0.13 and will be removed in 0.15, "
/homes/jh015/.conda/envs/hj_trans/lib/python3.7/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
ent tensor(0.3886) tensor(0.4654) tensor(2.5234) tensor(0.4057) tensor(12.4633)
cls_count [  27.   83.   71.   55.   64.   73.   57.   61.   47.   69.   50.   93.
   87.  191.  100.   55.   84.   36.   78.   91.   10.  121.   60.   71.
  119. 2504.] 0.003993610223642172 4357.0 0.029600638977635783 0.5747073674546707
cls_count [ 27.  83.  71.  55.  64.  73.  57.  61.  47.  69.  50.  93.  87. 191.
 100.  55.  84.  36.  78.  91.  10. 121.  60.  71. 119.] 0.0 10.0 191.0 0.05235602094240838
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
26
acc [50.98039216 90.12345679 55.12820513 71.66666667 28.125      68.96551724
 31.81818182 46.26865672 57.14285714 74.62686567 66.66666667 36.84210526
 90.66666667 83.52941176 61.01694915 60.24096386 73.07692308 25.88235294
 64.47368421 91.91919192  7.46268657 87.93103448 71.42857143 62.90322581
 78.04878049 74.0768938 ] 26 H_score 67.19159865998779
Task: office-home, Iter:0/1380; Accuracy = 61.96% / 61.48% / 74.08%
ent tensor(0.1431) tensor(0.2405) tensor(2.3920) tensor(0.3984) tensor(12.9651)
cls_count [  34.   97.  104.  104.  133.  109.  102.   77.   55.   92.   60.  162.
  112.  190.  131.   73.  127.   63.  109.   96.    7.  161.   70.   92.
  130. 1867.] 0.003749330476700589 4357.0 0.05334761649705409 0.42850585265090657
cls_count [ 34.  97. 104. 104. 133. 109. 102.  77.  55.  92.  60. 162. 112. 190.
 131.  73. 127.  63. 109.  96.   7. 161.  70.  92. 130.] 0.0 7.0 190.0 0.03684210526315789
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
26
acc [60.78431373 96.2962963  69.23076923 86.66666667 45.3125     81.03448276
 40.90909091 55.2238806  67.53246753 89.55223881 80.55555556 52.63157895
 98.66666667 90.58823529 69.49152542 73.4939759  78.84615385 35.29411765
 80.26315789 96.96969697  7.46268657 91.37931034 75.51020408 69.35483871
 85.36585366 58.8503997 ] 26 H_score 64.41288282579369
Task: office-home, Iter:69/1380; Accuracy = 70.66% / 71.14% / 58.85%
ent tensor(0.1119) tensor(0.1926) tensor(2.2912) tensor(0.2659) tensor(6.0466)
cls_count [  38.  113.  162.  142.  193.  157.  128.  108.   75.   94.   64.  196.
  120.  204.  196.   81.  174.   94.  135.   98.   14.  174.  109.  128.
  133. 1227.] 0.011409942950285249 4357.0 0.10203748981255094 0.28161579068166165
cls_count [ 38. 113. 162. 142. 193. 157. 128. 108.  75.  94.  64. 196. 120. 204.
 196.  81. 174.  94. 135.  98.  14. 174. 109. 128. 133.] 0.0 14.0 204.0 0.06862745098039216
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
26
acc [66.66666667 96.2962963  89.74358974 90.         51.5625     87.93103448
 43.93939394 70.14925373 84.41558442 91.04477612 83.33333333 64.9122807
 98.66666667 92.94117647 86.44067797 79.51807229 90.38461538 49.41176471
 82.89473684 98.98989899 10.44776119 91.37931034 87.75510204 82.25806452
 86.58536585 41.07346783] 26 H_score 53.883790263123515
Task: office-home, Iter:138/1380; Accuracy = 76.87% / 78.31% / 41.07%
ent tensor(0.0920) tensor(0.1684) tensor(2.2545) tensor(0.2057) tensor(3.7137)
cls_count [ 40. 122. 170. 160. 208. 174. 144. 114.  80.  96.  70. 222. 120. 210.
 240.  85. 194. 108. 127.  99.  28. 187. 133. 145. 135. 946.] 0.02959830866807611 4357.0 0.14422832980972516 0.2171218728482901
cls_count [ 40. 122. 170. 160. 208. 174. 144. 114.  80.  96.  70. 222. 120. 210.
 240.  85. 194. 108. 127.  99.  28. 187. 133. 145. 135.] 0.0 28.0 240.0 0.11666666666666667
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
26
acc [ 68.62745098  97.5308642   92.30769231  90.          51.5625
  89.65517241  45.45454545  74.62686567  87.01298701  91.04477612
  86.11111111  68.42105263  98.66666667  92.94117647  88.13559322
  80.72289157  90.38461538  49.41176471  80.26315789 100.
  10.44776119  96.55172414  93.87755102  83.87096774  87.80487805
  32.20403502] 26 H_score 45.891965004818104
Task: office-home, Iter:207/1380; Accuracy = 77.99% / 79.82% / 32.20%
ent tensor(0.0757) tensor(0.1514) tensor(2.0738) tensor(0.1814) tensor(2.9504)
cls_count [ 41. 121. 171. 170. 223. 179. 160. 116.  78.  98.  69. 229. 125. 208.
 246.  89. 208. 110. 128.  99.  40. 200. 135. 142. 137. 835.] 0.04790419161676647 4357.0 0.1687185628742515 0.1916456277254992
cls_count [ 41. 121. 171. 170. 223. 179. 160. 116.  78.  98.  69. 229. 125. 208.
 246.  89. 208. 110. 128.  99.  40. 200. 135. 142. 137.] 0.0 40.0 246.0 0.16260162601626016
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
26
acc [ 68.62745098  97.5308642   91.02564103  91.66666667  54.6875
  89.65517241  54.54545455  76.11940299  85.71428571  91.04477612
  86.11111111  68.42105263  98.66666667  90.58823529  89.83050847
  83.13253012  92.30769231  48.23529412  80.26315789 100.
  11.94029851  96.55172414  93.87755102  82.25806452  87.80487805
  28.81614008] 26 H_score 42.42966122890307
Task: office-home, Iter:276/1380; Accuracy = 78.44% / 80.42% / 28.82%
ent tensor(0.0665) tensor(0.1425) tensor(2.1249) tensor(0.1712) tensor(2.6454)
cls_count [ 41. 123. 174. 170. 221. 196. 161. 122.  81.  99.  68. 229. 125. 209.
 241.  90. 207. 113. 135.  99.  49. 203. 137. 142. 137. 785.] 0.05222929936305733 4357.0 0.1820127388535032 0.18016984163415195
cls_count [ 41. 123. 174. 170. 221. 196. 161. 122.  81.  99.  68. 229. 125. 209.
 241.  90. 207. 113. 135.  99.  49. 203. 137. 142. 137.] 0.0 41.0 241.0 0.17012448132780084
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
26
acc [ 68.62745098  98.7654321   92.30769231  91.66666667  54.6875
  91.37931034  56.06060606  79.10447761  85.71428571  92.53731343
  84.72222222  68.42105263  98.66666667  91.76470588  86.44067797
  83.13253012  90.38461538  48.23529412  80.26315789 100.
  11.94029851  96.55172414  93.87755102  82.25806452  87.80487805
  27.25542444] 26 H_score 40.73738092607256
Task: office-home, Iter:345/1380; Accuracy = 78.56% / 80.61% / 27.26%
ent tensor(0.0594) tensor(0.1373) tensor(2.0781) tensor(0.1664) tensor(2.4904)
cls_count [ 41. 126. 175. 171. 217. 196. 162. 119.  82. 106.  69. 228. 125. 209.
 243.  94. 204. 114. 140.  99.  51. 204. 141. 148. 137. 756.] 0.05423280423280423 4357.0 0.19052910052910052 0.17351388570117054
cls_count [ 41. 126. 175. 171. 217. 196. 162. 119.  82. 106.  69. 228. 125. 209.
 243.  94. 204. 114. 140.  99.  51. 204. 141. 148. 137.] 0.0 41.0 243.0 0.16872427983539096
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
26
acc [ 68.62745098  98.7654321   93.58974359  91.66666667  54.6875
  89.65517241  56.06060606  77.6119403   85.71428571  95.52238806
  86.11111111  68.42105263  98.66666667  90.58823529  86.44067797
  85.54216867  90.38461538  48.23529412  80.26315789 100.
  11.94029851  96.55172414  93.87755102  82.25806452  87.80487805
  26.18956985] 26 H_score 39.55259002218242
Task: office-home, Iter:414/1380; Accuracy = 78.66% / 80.76% / 26.19%
ent tensor(0.0504) tensor(0.1275) tensor(2.0770) tensor(0.1542) tensor(2.2072)
cls_count [ 41. 127. 174. 174. 218. 196. 161. 122.  85. 108.  68. 228. 131. 209.
 243.  96. 210. 114. 141.  99.  59. 204. 144. 153. 137. 715.] 0.057342657342657345 4357.0 0.20374825174825176 0.1641037411062658
cls_count [ 41. 127. 174. 174. 218. 196. 161. 122.  85. 108.  68. 228. 131. 209.
 243.  96. 210. 114. 141.  99.  59. 204. 144. 153. 137.] 0.0 41.0 243.0 0.16872427983539096
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
26
acc [ 68.62745098  98.7654321   93.58974359  91.66666667  54.6875
  89.65517241  56.06060606  79.10447761  85.71428571  95.52238806
  84.72222222  68.42105263  98.66666667  90.58823529  86.44067797
  85.54216867  92.30769231  48.23529412  80.26315789 100.
  13.43283582  96.55172414  93.87755102  82.25806452  87.80487805
  24.78111915] 26 H_score 37.940436984639206
Task: office-home, Iter:483/1380; Accuracy = 78.74% / 80.90% / 24.78%
ent tensor(0.0487) tensor(0.1226) tensor(2.1188) tensor(0.1420) tensor(1.8954)
cls_count [ 42. 127. 177. 174. 219. 197. 164. 124.  85. 110.  72. 230. 129. 209.
 249.  97. 213. 121. 140.  99.  64. 211. 150. 154. 137. 663.] 0.06334841628959276 4357.0 0.2228657616892911 0.15216892357126466
cls_count [ 42. 127. 177. 174. 219. 197. 164. 124.  85. 110.  72. 230. 129. 209.
 249.  97. 213. 121. 140.  99.  64. 211. 150. 154. 137.] 0.0 42.0 249.0 0.1686746987951807
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
26
